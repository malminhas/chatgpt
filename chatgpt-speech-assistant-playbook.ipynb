{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e45a1407-5ce0-49ae-8d0c-4d1ece602ca2",
   "metadata": {},
   "source": [
    "# ChatGPT Speech Assistant Playbook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100eddec-ff37-48e4-a1e5-9d56a37a94af",
   "metadata": {},
   "source": [
    "<p>\n",
    "Mal Minhas, v0.1<br>\n",
    "16.03.23\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea21ecf1-7cca-4f07-a3bc-4a1455c5ad6b",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28347c2-51e1-4f6a-8981-87a66c71160d",
   "metadata": {},
   "source": [
    "The recipe here was taken from the work of Faizan Bashir written up in a nice blog post [here](https://faizanbashir.me/building-a-chatgpt-based-ai-assistant-with-python-speech-to-text-and-text-to-speech-using-openai-apis).  The recipe outlined below is basically a copy of his work.  There are FOUR separate stages in this order:\n",
    "1. `speech_recognition` is used to record audio input to a WAV file using `portaudio`\n",
    "2. OpenAI [Whisper API](https://openai.com/research/whisper) is used to convert the WAV file to a text prompt as speech to text (STT). \n",
    "3. OpenAI `gpt-3.5-turbo` model is used to process the text prompt and generate a response\n",
    "4. [`pyttsx3`](https://pyttsx3.readthedocs.io/en/latest/engine.html) is used to vocalise the ChatGPT response as text to speech (TTS)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2f5936-f082-4b48-9ed2-829a5e8d64f3",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc5e68e-078f-4f84-8a0e-5d243b71d34f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Following Faizan's instructions for a MacBook:\n",
    "* Do a `brew install portaudio`\n",
    "* Create a virtualenv let's say `chatgpt`\n",
    "* `pip install SpeechRecognition, pyttsx3, requests` into `chatgpt`\n",
    "* Ensure you have a valid OpenAI API token in an `OPENAI_API_TOKEN` environment variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9729f611-e588-47d9-b71d-dad389c8d30e",
   "metadata": {},
   "source": [
    "Known Issues:\n",
    "* There is typically a 10 second or so gap between the utterance and the ChatGPT response\n",
    "* `pyttsx3` is blocking and once you start an utterance, you don't seem to be able to stop it from completing even if you interrupt the kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a738d7-be30-47b7-a43b-03ae9e391486",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ecb7344-8a87-40e3-a420-8bf1a16968f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import speech_recognition as sr\n",
    "import requests\n",
    "import pyttsx3\n",
    "\n",
    "AUDIO_FOLDER = \"./audio\"\n",
    "INPUT_FILENAME = \"microphone-results\"\n",
    "OPENAI_URL = \"https://api.openai.com/v1\"\n",
    "OPENAI_TOKEN = os.environ.get(\"OPENAI_API_TOKEN\")\n",
    "#OPENAI_MODEL = 'gpt-3.5-turbo'\n",
    "OPENAI_MODEL = 'gpt-4'\n",
    "assert(OPENAI_TOKEN)\n",
    "\n",
    "def recordSpeech():\n",
    "    ''' Obtain audio fr|om microphone using python speech_recognition and return speech WAV file. '''\n",
    "    print('[1.] Record audio using microphone')\n",
    "    # obtain audio from the microphone\n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        r.adjust_for_ambient_noise(source)\n",
    "        print(\"Say something then a gap to finish!\")\n",
    "        audio = r.listen(source)\n",
    "    audio_file_path = f\"{AUDIO_FOLDER}/{INPUT_FILENAME}.wav\"\n",
    "    if not os.path.exists(AUDIO_FOLDER):\n",
    "        os.mkdir(AUDIO_FOLDER)\n",
    "    # write audio to a WAV file\n",
    "    #print(f\"Generating WAV file, saving at location: {audio_file_path}\")\n",
    "    with open(audio_file_path, \"wb\") as f:\n",
    "        f.write(audio.get_wav_data())\n",
    "    return audio_file_path\n",
    "\n",
    "def convertSpeechToText(audio_file_path):\n",
    "    ''' Convert speech WAV file to text. '''\n",
    "    print('[2.] Call to Whisper API\\'s to get the STT response')\n",
    "    url = f'{OPENAI_URL}/audio/transcriptions'\n",
    "    data = {\n",
    "        'model': 'whisper-1',\n",
    "        'file': audio_file_path,\n",
    "    }\n",
    "    files = {\n",
    "        'file': open(audio_file_path, \"rb\")\n",
    "    }\n",
    "    headers = { 'Authorization' : f'Bearer {OPENAI_TOKEN}' }\n",
    "    response = requests.post(url, files=files, data=data, headers=headers)\n",
    "    #print(\"Status Code\", response.status_code)\n",
    "    speech_to_text = response.json()['text']\n",
    "    #print(\"Response from Whisper API's\", speech_to_text)\n",
    "    return speech_to_text\n",
    "\n",
    "def getChatGPTresponse(prompt_text):\n",
    "    ''' '''\n",
    "    print(f'[3.] Querying ChatGPT model with the STT response data for prompt:\\n\"{prompt_text}\"')\n",
    "    url = f'{OPENAI_URL}/chat/completions'\n",
    "    data = {\n",
    "        'model': OPENAI_MODEL,\n",
    "        'messages': [\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': prompt_text\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    headers = { 'Authorization' : f'Bearer {OPENAI_TOKEN}' }\n",
    "    response = requests.post(url, json=data, headers=headers)\n",
    "    #print(\"Status Code\", response.status_code)\n",
    "    chatgpt_response = response.json()['choices'][0]['message']['content'].strip()\n",
    "    print(f'Response from ChatGPT \\'{OPENAI_MODEL}\\' model:\\n\"{chatgpt_response}\"')\n",
    "    return chatgpt_response\n",
    "\n",
    "def convertTextToSpeech(chatgpt_response, speed=200):\n",
    "    engine = pyttsx3.init()\n",
    "    print(f'[4.] Try to convert TTS from the response, speed={speed}')\n",
    "    def onStart(name):\n",
    "        print(f'started-utterance')\n",
    "    def onWord(name, location, length):\n",
    "        pass\n",
    "    def onError(name, location, length):\n",
    "        print(f'error: {name}')\n",
    "        engine.stop()\n",
    "    def onEnd(name, completed):\n",
    "        print(f'finished-utterance')\n",
    "    started = engine.connect('started-utterance', onStart)\n",
    "    error = engine.connect('error', onError)\n",
    "    #engine.connect('started-word', onWord)\n",
    "    finished = engine.connect('finished-utterance', onEnd)\n",
    "    engine.setProperty('rate', speed)\n",
    "    #print(\"Converting text to speech...\")\n",
    "    engine.say(chatgpt_response)\n",
    "    try:\n",
    "        engine.runAndWait()\n",
    "    except Exception as e:\n",
    "        print(f'stopping because \"{e}\"')\n",
    "    engine.disconnect(started)\n",
    "    engine.disconnect(error)\n",
    "    engine.disconnect(finished)\n",
    "    engine.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62f1c9fc-7e4d-49c2-b09d-14d761753d43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.] Record audio using microphone\n",
      "Say something then a gap to finish!\n",
      "[2.] Call to Whisper API's to get the STT response\n",
      "[3.] Querying ChatGPT model with the STT response data for prompt:\n",
      "\"Why is the sky blue?\"\n",
      "Response from ChatGPT 'gpt-4' model:\n",
      "\"The sky appears blue because of a phenomenon called Rayleigh scattering. When sunlight enters the Earth's atmosphere, it is made up of a spectrum of colors. The gas molecules and other small particles in the atmosphere scatter the sunlight in all directions. \n",
      "\n",
      "Blue light has a shorter wavelength and is scattered more easily than other colors with longer wavelengths, like red and yellow. As a result, when we look at the sky, the blue light is scattered across the atmosphere and dominates our field of vision, making the sky appear blue.\"\n",
      "[4.] Try to convert TTS from the response, speed=200\n",
      "started-utterance\n",
      "finished-utterance\n"
     ]
    }
   ],
   "source": [
    "speech = recordSpeech()\n",
    "prompt_text = convertSpeechToText(speech)\n",
    "chatgpt_response = getChatGPTresponse(prompt_text)\n",
    "convertTextToSpeech(chatgpt_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
